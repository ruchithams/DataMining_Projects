{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Math library\n",
    "import math\n",
    "from IPython import display\n",
    "\n",
    "# Importing matplotlib for better graphical visualization\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import numpy for numerical computing\n",
    "import numpy as np\n",
    "# import pandas for dataframe\n",
    "import pandas as pd\n",
    "\n",
    "import missingno as msno\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale, StandardScaler, normalize\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "\n",
    "# import PCA \n",
    "from sklearn.decomposition import PCA\n",
    "# import kmeans for clustering \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# import python plot\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Libraries of model to make predictions and to validate the models working\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading online retail dataset dataset\n",
    "data = pd.read_excel(\"/Users/ruchitha/Desktop/DataMining_Projects/Online-retail-Analysis/clean_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total cost of the product purchased\n",
    "total_cost = data['Quantity'] * data['UnitPrice']\n",
    "data_new = data[(data['total_cost'] >0) & (data['total_cost'] < 100)]\n",
    "spend_label = []\n",
    "for i in range(0,len(data_new),1):\n",
    "    if data_new['total_cost'].iloc[i] < 11:\n",
    "        spend_label.append(0)\n",
    "    elif data_new['total_cost'].iloc[i] >30:\n",
    "        spend_label.append(2)\n",
    "    else:\n",
    "        spend_label.append(1)\n",
    "# adding an additonal spent_label feature\n",
    "data_new['spend_label'] = spend_label\n",
    "#  Creating dummies for description\n",
    "dummy_1 = pd.get_dummies(data=data_new['Description'])\n",
    "new_ds_1 = pd.concat([data_new, dummy_1], axis=1)\n",
    "# drop the columns that have been now been replaced  by derived features \n",
    "unwanted_cols = ['Quantity','StockCode','InvoiceDate','InvoiceNo','UnitPrice','Description','spend_label','CustomerID']\n",
    "new_ds_1 = new_ds_1.drop(unwanted_cols, axis=1)\n",
    "new_ds_1 = new_ds_1.reset_index(drop=True)\n",
    "# selecting the features for model training\n",
    "new_ds_3 = new_ds_1.copy()\n",
    "# deleting the target colum from features set\n",
    "del new_ds_3['Country']\n",
    "# taget for training model\n",
    "ydata2 = new_ds_1['Country']\n",
    "# convert ydata2 to integer\n",
    "ydata2 = ydata2.astype('category')\n",
    "normalized_data2 = preprocessing.normalize(new_ds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GradientBoostin: LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's multi_logloss: 1.13298 + 0.0012676\n",
      "[40]\tcv_agg's multi_logloss: 0.777325 + 0.00124495\n",
      "[60]\tcv_agg's multi_logloss: 0.657756 + 0.00140435\n",
      "[80]\tcv_agg's multi_logloss: 0.612428 + 0.00166689\n",
      "[100]\tcv_agg's multi_logloss: 0.593498 + 0.00189162\n",
      "[120]\tcv_agg's multi_logloss: 0.583033 + 0.00198964\n",
      "[140]\tcv_agg's multi_logloss: 0.577493 + 0.00200542\n",
      "[160]\tcv_agg's multi_logloss: 0.574449 + 0.00205914\n",
      "[180]\tcv_agg's multi_logloss: 0.572362 + 0.00214975\n",
      "[200]\tcv_agg's multi_logloss: 0.570935 + 0.00220593\n",
      "[220]\tcv_agg's multi_logloss: 0.570193 + 0.00222563\n",
      "[240]\tcv_agg's multi_logloss: 0.569572 + 0.00230161\n",
      "[260]\tcv_agg's multi_logloss: 0.571507 + 0.00441704\n",
      "[280]\tcv_agg's multi_logloss: 0.571669 + 0.00501266\n",
      "[300]\tcv_agg's multi_logloss: 0.569287 + 0.00229977\n",
      "[320]\tcv_agg's multi_logloss: 0.569241 + 0.00229556\n",
      "[340]\tcv_agg's multi_logloss: 0.569307 + 0.00226408\n",
      "[360]\tcv_agg's multi_logloss: 0.570741 + 0.00424561\n",
      "[380]\tcv_agg's multi_logloss: 0.569914 + 0.00275463\n",
      "[400]\tcv_agg's multi_logloss: 0.57007 + 0.00279519\n",
      "[420]\tcv_agg's multi_logloss: 0.570336 + 0.00279897\n"
     ]
    }
   ],
   "source": [
    "# convert string label to float & make new sets for LightGBM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "lb = LabelEncoder()\n",
    "ydata_float = lb.fit_transform(ydata2)\n",
    "# splittng model data\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(normalized_data2,ydata_float,test_size = 0.3, random_state = 8418) \n",
    "train_data=lgb.Dataset(xtrain,label=ytrain)\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':37,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 17,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 17}\n",
    "\n",
    "lgb_cv = lgb.cv(params, train_data, num_boost_round=10000, nfold=5, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=100)\n",
    "\n",
    "nround = lgb_cv['multi_logloss-mean'].index(np.min(lgb_cv['multi_logloss-mean']))\n",
    "lgbm_model2 = lgb.train(params, train_data, num_boost_round=nround)\n",
    "#predicting on test set\n",
    "ypred=lgbm_model2.predict(xtest)\n",
    "predictions = []\n",
    "\n",
    "for x in ypred:\n",
    "    predictions.append(np.argmax(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.20%\n",
      "Recall: 89.1980283598477 %\n",
      "Precision: 89.1980283598477 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest, predictions)\n",
    "# model perfomance scores\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('Recall:', recall_score(ytest, predictions,average=\"micro\")*100,\"%\")\n",
    "print('Precision:', precision_score(ytest, predictions,average=\"micro\")*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
